{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2160038b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "509f78df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "276a7ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbab7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "# Use matplotlib to visualize the sample distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "# Use jieba to split the word\n",
    "import jieba\n",
    "from gensim.models import KeyedVectors\n",
    "# use genism to load pre-training word vector\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Use bz2 to unzip the file\n",
    "import bz2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af4fe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the dowloaded zip file into embeddings folders\n",
    "# unzip the downloaded Chinese-word-vectors file\n",
    "with open(\"sgns.zhihu.bigram\", 'wb') as new_file, open(\"C:/Users/12529/Desktop/Cityu/data/embeddings/sgns.zhihu.bigram.bz2\", 'rb') as file:\n",
    "    decompressor = bz2.BZ2Decompressor()\n",
    "    for data in iter(lambda : file.read(100 * 1024), b''):\n",
    "        new_file.write(decompressor.decompress(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f3d4657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use genism to load pre-training word vector\n",
    "cn_model = KeyedVectors.load_word2vec_format('sgns.zhihu.bigram', \n",
    "                                             binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4abeadb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词向量的长度为300\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.023013,  0.099276, -0.188544,  0.014892, -0.140755, -0.275439,\n",
       "       -0.095019,  0.064443, -0.205539, -0.046788, -0.229846,  0.408116,\n",
       "        0.173516, -0.053986,  0.278121, -0.487348,  0.006504,  0.028538,\n",
       "        0.321313,  0.185489,  0.20306 ,  0.034164, -0.163552, -0.02637 ,\n",
       "       -0.166576, -0.070172, -0.12176 , -0.017719,  0.218962,  0.21611 ,\n",
       "       -0.127903, -0.001921, -0.290569,  0.077451,  0.026128,  0.062851,\n",
       "        0.045356, -0.007478, -0.057944,  0.051172, -0.232546, -0.172068,\n",
       "       -0.247718,  0.099174,  0.127989,  0.098246,  0.125703,  0.071   ,\n",
       "        0.006947,  0.078257, -0.109834, -0.232685, -0.005075, -0.080271,\n",
       "       -0.153889, -0.030573, -0.155043,  0.169404, -0.008193,  0.069078,\n",
       "        0.070398,  0.327962, -0.087014,  0.033845,  0.185293, -0.062712,\n",
       "        0.04409 ,  0.233994,  0.319075,  0.189237,  0.008978,  0.049041,\n",
       "       -0.186978, -0.240406, -0.169748,  0.089397,  0.220555,  0.071285,\n",
       "       -0.140622,  0.13056 ,  0.157906, -0.09437 , -0.022758,  0.061752,\n",
       "       -0.067784, -0.03759 , -0.056957,  0.022269,  0.087674, -0.138748,\n",
       "       -0.214596,  0.127401, -0.055197, -0.08962 ,  0.062884,  0.010669,\n",
       "        0.078627, -0.086867,  0.100926,  0.183121,  0.297536,  0.295085,\n",
       "        0.052975,  0.094304, -0.018966,  0.10882 ,  0.091041,  0.095472,\n",
       "        0.099485, -0.188817,  0.016729,  0.415112,  0.18422 ,  0.243796,\n",
       "       -0.150603, -0.008642,  0.036927,  0.099739, -0.276099,  0.034635,\n",
       "        0.078768,  0.165521, -0.006722, -0.266745, -0.075102, -0.013305,\n",
       "       -0.061178, -0.117194,  0.226125,  0.023608,  0.294389,  0.129689,\n",
       "        0.0761  ,  0.060009,  0.166818, -0.344912, -0.020178,  0.052866,\n",
       "        0.121578,  0.058672, -0.199113,  0.113143,  0.039781, -0.177291,\n",
       "       -0.273799, -0.049399,  0.184403,  0.544291,  0.023921,  0.115633,\n",
       "       -0.08788 , -0.043937, -0.156396, -0.019345,  0.33077 ,  0.362293,\n",
       "       -0.142043, -0.064321,  0.022148,  0.056429,  0.212164, -0.011472,\n",
       "       -0.356246,  0.006737,  0.05381 , -0.14093 , -0.277371,  0.051761,\n",
       "        0.295368,  0.095943,  0.050462, -0.050061,  0.077693, -0.00335 ,\n",
       "       -0.004887, -0.088464, -0.236442,  0.25466 , -0.330043, -0.021434,\n",
       "        0.051665,  0.07379 ,  0.154656,  0.235011,  0.17419 , -0.116778,\n",
       "        0.142752, -0.084396, -0.127055,  0.205002, -0.289404, -0.036417,\n",
       "       -0.078818, -0.11276 ,  0.015815, -0.130915, -0.047751, -0.163156,\n",
       "       -0.105089,  0.009451,  0.217415,  0.088615,  0.011201, -0.110633,\n",
       "        0.244465,  0.230177, -0.070185,  0.081149,  0.037685, -0.031509,\n",
       "       -0.193795, -0.215764, -0.179588, -0.148191,  0.083373,  0.285842,\n",
       "        0.203793,  0.065659, -0.006738,  0.226223,  0.110056,  0.297404,\n",
       "        0.110036, -0.14115 ,  0.212767, -0.133186, -0.079839,  0.233012,\n",
       "       -0.04479 , -0.13179 , -0.001686, -0.059578, -0.016801, -0.035031,\n",
       "        0.086657, -0.06941 , -0.12827 ,  0.134985,  0.104144,  0.158178,\n",
       "       -0.152484,  0.117819,  0.058122, -0.045868, -0.06307 ,  0.121974,\n",
       "       -0.063508, -0.236058,  0.140546,  0.102547,  0.176208, -0.157135,\n",
       "       -0.075037,  0.130363,  0.351965, -0.227436, -0.02365 , -0.082319,\n",
       "        0.04215 ,  0.120417,  0.075681, -0.081921, -0.19637 ,  0.064087,\n",
       "       -0.251134, -0.275794, -0.008691, -0.090238,  0.035805,  0.122451,\n",
       "        0.107503, -0.337783,  0.055334,  0.15525 ,  0.101346,  0.12752 ,\n",
       "       -0.058039,  0.021558,  0.409527, -0.176278,  0.044184,  0.033894,\n",
       "       -0.004013,  0.021158, -0.183294,  0.262507,  0.017212, -0.126863,\n",
       "        0.124105, -0.116016, -0.0775  , -0.162946, -0.247953, -0.05541 ,\n",
       "       -0.050814, -0.038711,  0.080194,  0.16379 ,  0.252623, -0.066029],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = cn_model['香港城市大学'].shape[0]\n",
    "print('词向量的长度为{}'.format(embedding_dim))\n",
    "cn_model['香港城市大学']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c2e64f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('出轨', 0.6100173592567444)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Similarity\n",
    "cn_model.most_similar(positive=['女人','劈腿'], negative=['男人'], topn=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3f47a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在 老师 会计师 程序员 律师 医生 老人 中:\n",
      "不是同一类别的词为: 老人\n"
     ]
    }
   ],
   "source": [
    "test_words = '老师 会计师 程序员 律师 医生 老人'\n",
    "test_words_result = cn_model.doesnt_match(test_words.split())\n",
    "print('在 '+test_words+' 中:\\n不是同一类别的词为: %s' %test_words_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ebb4532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "样本总共: 4000\n"
     ]
    }
   ],
   "source": [
    "# Samples are stored in 'pos' folder and 'neg' folder\n",
    "# There are 2,000 txt files in each folder, each one contains a review\n",
    "import os\n",
    "pos_txts = os.listdir('chinese_sentiment-master/语料/pos')\n",
    "neg_txts = os.listdir('chinese_sentiment-master/语料/neg')\n",
    "print( '样本总共: '+ str(len(pos_txts) + len(neg_txts)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "408dc5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put all the reviews in a list, each review becomes a string\n",
    "\n",
    "train_texts_orig = []\n",
    "\n",
    "for i in range(len(pos_txts)):\n",
    "    with open('C:/Users/12529/Desktop/datala/chinese_sentiment-master/语料/pos/'+pos_txts[i], 'r', errors='ignore') as f:\n",
    "        text = f.read().strip()\n",
    "        train_texts_orig.append(text)\n",
    "        f.close()\n",
    "for i in range(len(neg_txts)):\n",
    "    with open('C:/Users/12529/Desktop/datala/chinese_sentiment-master/语料/neg/'+neg_txts[i], 'r', errors='ignore') as f:\n",
    "        text = f.read().strip()\n",
    "        train_texts_orig.append(text)\n",
    "        f.close()\n",
    "        \n",
    "len(train_texts_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90a374e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-gpu in c:\\users\\12529\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.0.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.7.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.15.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.6.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (12.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.22.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.3.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.36.2)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.3.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.7.4.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.42.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.2.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.7.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.7.0)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.18.5)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (3.19.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.12.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.1.2)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (2.10.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (2.3.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (1.8.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (2.25.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu) (3.3.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu) (4.8.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu) (3.4.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu) (1.26.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\12529\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu) (3.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow-gpu --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfc797cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use keras in tensorflow to build the model\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c23a223",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, GRU, Embedding, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60ee0b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "428f5e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e482a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1637ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e85a267b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c66a99b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\12529\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.546 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# Segmentation and tokenize\n",
    "# train_tokens is a list with 4,000 strings\n",
    "train_tokens = []\n",
    "for text in train_texts_orig:\n",
    "    # Remove the punctuation \n",
    "    text = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\",text)\n",
    "    # Participle\n",
    "    cut = jieba.cut(text)\n",
    "    # The output is a generator\n",
    "    # convert generator to list\n",
    "    cut_list = [ i for i in cut ]\n",
    "    for i, word in enumerate(cut_list):\n",
    "        try:\n",
    "            # convert word to index\n",
    "            cut_list[i] = cn_model.key_to_index[word]\n",
    "        except KeyError:\n",
    "            cut_list[i] = 0\n",
    "    train_tokens.append(cut_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "300ba4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tokens = [ len(tokens) for tokens in train_tokens ]\n",
    "num_tokens = np.array(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ade69ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.42575"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bc06d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1540"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1d8a52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log(num_tokens), bins = 100)\n",
    "plt.xlim((0,10))\n",
    "plt.ylabel('number of tokens')\n",
    "plt.xlabel('length of tokens')\n",
    "plt.title('Distribution of tokens length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a96092c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "236"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking the mean of the tokens and adding two standard deviations\n",
    "# We assumed that the tokens lengths were normally distributed.\n",
    "# the value of max_tokens could contain 95% of the tokens\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0559c1ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9565"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 95% of the tokens could be covered when the length is 236\n",
    "np.sum( num_tokens < max_tokens ) / len(num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dc9a7b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert these tokens to texts for us to read\n",
    "def reverse_tokens(tokens):\n",
    "    text = ''\n",
    "    for i in tokens:\n",
    "        if i != 0:\n",
    "            text = text + cn_model.index_to_key[i]\n",
    "        else:\n",
    "            text = text + ' '\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfc3aeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse = reverse_tokens(train_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "489e6f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'早餐太差无论去多少人那边也不加食品的酒店应该重视一下这个问题了房间本身很好'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae810a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c363612",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 240000\n",
    "embedding_matrixx = np.zeros((num_words, embedding_dim))\n",
    "# embedding_matrix: [num_words，embedding_dim] \n",
    "# 250000 * 300\n",
    "for i in range(num_words):\n",
    "    embedding_matrixx[i,:] = cn_model[cn_model.index_to_key[i]]\n",
    "embedding_matrixx = embedding_matrixx.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61813a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum( cn_model[cn_model.index_to_key[333]] == embedding_matrixx[333] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6fa38e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(240000, 300)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrixx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbc4560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pad = pad_sequences(train_tokens, maxlen=max_tokens,\n",
    "                            padding='pre', truncating='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dadb76f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,    40,   562,     1,  1845,  2967,\n",
       "          34,    72,    38,    15,  5376,   184,  7524,   348,     0,\n",
       "       29229,    18,     8,    58,   632,     1,  4246,   223,    10,\n",
       "         369,  7763])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pad[ train_pad>=num_words ] = 0\n",
    "train_pad[233]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "002ab2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepared the target vector. The first 2,000 samples were 1, and the last 2,000 samples were 0. \n",
    "train_target = np.concatenate( (np.ones(2000),np.zeros(2000)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d22929e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the training sample from the test sample\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2f020088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 90% of the samples were used for training and the remaining 10% were used for testing\n",
    "# The random_state was also used to scramble the order of samples\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_pad,\n",
    "                                                    train_target,\n",
    "                                                    test_size=0.1,\n",
    "                                                    random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c7a7d4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                        房间很大还有海景阳台走出酒店就是沙滩非常不错唯一遗憾的就是不能刷银联卡不方便\n",
      "class:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Check the samples\n",
    "print(reverse_tokens(X_train[35]))\n",
    "print('class: ',y_train[35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7af4cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classifying samples using LSTM\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "267b3d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os (Release the memory)\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14c30f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the first layer, the embedding layer.\n",
    "model.add(Embedding(num_words,\n",
    "                    embedding_dim,\n",
    "                    weights=[embedding_matrixx],\n",
    "                    input_length=max_tokens,\n",
    "                    trainable=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d833b794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the second and third layer\n",
    "model.add(Bidirectional(LSTM(units=32, return_sequences=True)))\n",
    "model.add(LSTM(units=16, return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "688eed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code of GRU\n",
    "# model.add(GRU(units=32, return_sequences=True))\n",
    "# model.add(GRU(units=16, return_sequences=True))\n",
    "# model.add(GRU(units=4, return_sequences=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46912366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the full connected layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Use adam to optimize with 0.001 learning rate\n",
    "optimizer = Adam(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a1562e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2dd73b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 236, 300)          72000000  \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 236, 64)          85248     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 16)                5184      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 72,090,449\n",
      "Trainable params: 90,449\n",
      "Non-trainable params: 72,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f60216a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a checkpoint\n",
    "path_checkpoint = 'sentiment_checkpoint.keras'\n",
    "checkpoint = ModelCheckpoint(filepath=path_checkpoint, monitor='val_loss',\n",
    "                                      verbose=1, save_weights_only=True,\n",
    "                                      save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b7f41f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to open file (unable to open file: name = 'sentiment_checkpoint.keras', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"
     ]
    }
   ],
   "source": [
    "# load the trained model\n",
    "try:\n",
    "    model.load_weights(path_checkpoint)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a0f90c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an early stoping\n",
    "earlystopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "68c30a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically reduce the learning rate\n",
    "lr_reduction = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1, min_lr=1e-5, patience=0,\n",
    "                                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "15193de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define these three callback function\n",
    "callbacks = [\n",
    "    earlystopping, \n",
    "    checkpoint,\n",
    "    lr_reduction\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "150643b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.6000 - accuracy: 0.6914\n",
      "Epoch 00001: val_loss improved from inf to 0.49498, saving model to sentiment_checkpoint.keras\n",
      "26/26 [==============================] - 15s 440ms/step - loss: 0.6000 - accuracy: 0.6914 - val_loss: 0.4950 - val_accuracy: 0.7639 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.4158 - accuracy: 0.8201\n",
      "Epoch 00002: val_loss improved from 0.49498 to 0.45642, saving model to sentiment_checkpoint.keras\n",
      "26/26 [==============================] - 9s 344ms/step - loss: 0.4158 - accuracy: 0.8201 - val_loss: 0.4564 - val_accuracy: 0.8056 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.3923 - accuracy: 0.8324\n",
      "Epoch 00003: val_loss did not improve from 0.45642\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "26/26 [==============================] - 8s 324ms/step - loss: 0.3923 - accuracy: 0.8324 - val_loss: 0.5245 - val_accuracy: 0.7639 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.3608 - accuracy: 0.8481\n",
      "Epoch 00004: val_loss improved from 0.45642 to 0.35829, saving model to sentiment_checkpoint.keras\n",
      "26/26 [==============================] - 9s 352ms/step - loss: 0.3608 - accuracy: 0.8481 - val_loss: 0.3583 - val_accuracy: 0.8444 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.3189 - accuracy: 0.8756\n",
      "Epoch 00005: val_loss did not improve from 0.35829\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "26/26 [==============================] - 9s 332ms/step - loss: 0.3189 - accuracy: 0.8756 - val_loss: 0.3584 - val_accuracy: 0.8250 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.3070 - accuracy: 0.8821\n",
      "Epoch 00006: val_loss improved from 0.35829 to 0.35331, saving model to sentiment_checkpoint.keras\n",
      "26/26 [==============================] - 9s 354ms/step - loss: 0.3070 - accuracy: 0.8821 - val_loss: 0.3533 - val_accuracy: 0.8333 - lr: 1.0000e-05\n",
      "Epoch 7/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.3056 - accuracy: 0.8830\n",
      "Epoch 00007: val_loss did not improve from 0.35331\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "26/26 [==============================] - 9s 333ms/step - loss: 0.3056 - accuracy: 0.8830 - val_loss: 0.3535 - val_accuracy: 0.8306 - lr: 1.0000e-05\n",
      "Epoch 8/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.3048 - accuracy: 0.8840\n",
      "Epoch 00008: val_loss did not improve from 0.35331\n",
      "26/26 [==============================] - 9s 330ms/step - loss: 0.3048 - accuracy: 0.8840 - val_loss: 0.3536 - val_accuracy: 0.8278 - lr: 1.0000e-05\n",
      "Epoch 9/20\n",
      "26/26 [==============================] - ETA: 0s - loss: 0.3036 - accuracy: 0.8836\n",
      "Epoch 00009: val_loss did not improve from 0.35331\n",
      "26/26 [==============================] - 9s 339ms/step - loss: 0.3036 - accuracy: 0.8836 - val_loss: 0.3543 - val_accuracy: 0.8306 - lr: 1.0000e-05\n",
      "Epoch 00009: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x214a89ae7c0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start training\n",
    "model.fit(X_train, y_train,\n",
    "          validation_split=0.1, \n",
    "          epochs=20,\n",
    "          batch_size=128,\n",
    "          callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d2c5ee34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 48ms/step - loss: 0.3602 - accuracy: 0.8675\n",
      "Accuracy:86.75%\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test, y_test)\n",
    "print('Accuracy:{0:.2%}'.format(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90b3884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sentiment(text):\n",
    "    print(text)\n",
    "    # Remove the punctuation\n",
    "    text = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+——！，。？、~@#￥%……&*（）]+\", \"\",text)\n",
    "    # Participle\n",
    "    cut = jieba.cut(text)\n",
    "    cut_list = [ i for i in cut ]\n",
    "    # Tokenize\n",
    "    for i, word in enumerate(cut_list):\n",
    "        try:\n",
    "            cut_list[i] = cn_model.key_to_index[word]\n",
    "        except KeyError:\n",
    "            cut_list[i] = 0\n",
    "    # Dadding\n",
    "    tokens_pad = pad_sequences([cut_list], maxlen=max_tokens,\n",
    "                           padding='pre', truncating='pre')\n",
    "    # Prediction\n",
    "    result = model.predict(x=tokens_pad)\n",
    "    coef = result[0][0]\n",
    "    if coef >= 0.5:\n",
    "        print('是一例正面评价','output=%.2f'%coef)\n",
    "    else:\n",
    "        print('是一例负面评价','output=%.2f'%coef)\n",
    "    return coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7adec53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jerry最帅了哈哈啊哈哈\n",
      "是一例正面评价 output=0.79\n"
     ]
    }
   ],
   "source": [
    "test_list = [\n",
    "    'jerry最帅了哈哈啊哈哈'\n",
    "]\n",
    "for text in test_list:\n",
    "    predict_sentiment(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5a47d040",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>username</th>\n",
       "      <th>comment</th>\n",
       "      <th>datentime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>是富婆本人没错了</td>\n",
       "      <td>我刚刚已经把其他所有山寨币卖了，全冲狗狗币，over，愿意一起的就跟！注意风险控制8号之前上...</td>\n",
       "      <td>05月05日 14:49  来自 微博视频号</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Tokenism通证主义</td>\n",
       "      <td>狗狗币\\n1.不能做空狗狗币，不然你会倾家荡产。\\n2.买一枚狗狗币，留给孩子。\\n3.人...</td>\n",
       "      <td>05月05日 15:12  来自 狗狗币超话</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>会火大叔</td>\n",
       "      <td>很多人都问我怎么购买狗狗币，\\n\\n最新最详细的教程来了火火??????\\n\\n#狗狗币大涨...</td>\n",
       "      <td>05月05日 12:23  来自 微博视频号</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Crypto熊猫</td>\n",
       "      <td>老韭菜老觉得有庄要害他，所以简单到无脑的送钱行情全踏空，亏钱行情因为复杂，一个都没落下\\n\\...</td>\n",
       "      <td>05月04日 20:19  来自 iPhone 12 Pro Max(海蓝色)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>日安小姐</td>\n",
       "      <td>#狗狗币上涨#还有不知道怎么买的可以看下这条的评论～</td>\n",
       "      <td>05月04日 01:50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      username  \\\n",
       "0           0      是富婆本人没错了   \n",
       "1           1  Tokenism通证主义   \n",
       "2           2          会火大叔   \n",
       "3           3      Crypto熊猫   \n",
       "4           4          日安小姐   \n",
       "\n",
       "                                             comment  \\\n",
       "0  我刚刚已经把其他所有山寨币卖了，全冲狗狗币，over，愿意一起的就跟！注意风险控制8号之前上...   \n",
       "1  狗狗币\\n1.不能做空狗狗币，不然你会倾家荡产。\\n2.买一枚狗狗币，留给孩子。\\n3.人...   \n",
       "2  很多人都问我怎么购买狗狗币，\\n\\n最新最详细的教程来了火火??????\\n\\n#狗狗币大涨...   \n",
       "3  老韭菜老觉得有庄要害他，所以简单到无脑的送钱行情全踏空，亏钱行情因为复杂，一个都没落下\\n\\...   \n",
       "4                         #狗狗币上涨#还有不知道怎么买的可以看下这条的评论～   \n",
       "\n",
       "                                 datentime  \n",
       "0                   05月05日 14:49  来自 微博视频号  \n",
       "1                   05月05日 15:12  来自 狗狗币超话  \n",
       "2                   05月05日 12:23  来自 微博视频号  \n",
       "3  05月04日 20:19  来自 iPhone 12 Pro Max(海蓝色)  \n",
       "4                             05月04日 01:50  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('dogecoin4.28-5.8.csv', encoding='utf-8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d79ffd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testcom = data['comment']\n",
    "testcom2 = []\n",
    "for i in testcom:\n",
    "    testcom2.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "34b0232a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我刚刚已经把其他所有山寨币卖了，全冲狗狗币，over，愿意一起的就跟！注意风险控制8号之前上升空间都很大！现在市值已经排第一了，越多人买就涨得越快！！我愿意用狗子币赌一个未来～（我男朋友的山寨币也都被我卖了，给他全部安排了狗狗币）\n",
      "\n",
      "#狗狗币# #狗狗币大涨#\n",
      "L是富婆本人没错了的微博视频 收起d\n",
      "是一例负面评价 output=0.13\n",
      "狗狗币\n",
      "1.不能做空狗狗币，不然你会倾家荡产。\n",
      "2.买一枚狗狗币，留给孩子。\n",
      "3.人生建议：不赌 不嫖 不吸毒 坚持定投狗狗币。\n",
      "4.人生如戏，唯有爱与狗狗币不可辜负。\n",
      "是一例负面评价 output=0.08\n",
      "很多人都问我怎么购买狗狗币，\n",
      "\n",
      "最新最详细的教程来了火火??????\n",
      "\n",
      "#狗狗币大涨##怎么购买狗狗币#\n",
      "#怎么买狗狗币# L会火大叔的微博视频\n",
      "是一例负面评价 output=0.32\n",
      "老韭菜老觉得有庄要害他，所以简单到无脑的送钱行情全踏空，亏钱行情因为复杂，一个都没落下\n",
      "\n",
      "狗狗币#狗狗币大涨##狗狗币#\n",
      "是一例负面评价 output=0.13\n",
      "#狗狗币上涨#还有不知道怎么买的可以看下这条的评论～\n",
      "是一例正面评价 output=0.54\n",
      "#狗狗币# 再次领涨？到底怎么了，是这个世界太疯狂还是我们太无知？今年为止已经涨了140倍，根据欧易OKEx显示，今日最高价格已经接近0.7美金了，24小时成交额都超过了以太坊，很多人都在猜测狗狗币会不会突破1美金，那这么火热的狗狗币，到底是什么？还能下手吗？现在买还来的及吗？做决定之前，不如先点击下方视频，一分钟了解神奇的狗狗币 #狗狗币大涨# #狗狗币上涨# O网页链接 收起d\n",
      "是一例负面评价 output=0.22\n",
      "【#狗狗币#飙升50% 市场狂欢一度令Robinhood系统瘫痪】在加密货币世界中，动物精神非常活跃且狂热，狗狗币直线飙升50%，Robinhood的交易App一度因此瘫痪。Miller Tabak +Co．的首席市场策略师Matt Maley表示，“从当初一个笑话到现在变得如此流行，真是太令人吃惊了。”O狗狗币飙升50% 市场狂欢一度令Robinhood系统瘫痪\n",
      "是一例负面评价 output=0.13\n",
      "#比特币大佬看衰狗狗币#：建议不要购买狗狗币，无知的投资者赶紧卖了吧。\n",
      "是一例负面评价 output=0.16\n",
      "#狗狗币# 的创始人有两位，一位是它的开发者比利·马库斯，另一位是它的概念发起人杰克逊·帕尔默。但两个人都在2015年先后卖出了所持有的所有狗狗币，马库斯卖出狗币后买了辆二手本田，然后就成了一个普通的打工人。\n",
      "\n",
      "当时，一个狗狗币的价格仅约为0.0001美元，即使是按照6000美元的二手本田的售价来计算，马库斯此前手里应该持有超过6千万个狗狗币，而如果他当年不卖出，今天这些狗狗币的价值将超过3600万美元。\n",
      "\n",
      "而现如今狗狗币的代言人马斯克，却用狗币疯狂赚钱造火箭并准备带着它上火星。\n",
      "\n",
      "你们看好狗币么？ 收起d\n",
      "是一例负面评价 output=0.09\n",
      "【赶紧收藏】\n",
      "\n",
      "很多人都问我怎么购买狗狗币，比特币\n",
      "\n",
      "2021最新最详细的视频教程来了火火??????\n",
      "\n",
      "老规矩，评论区随机送狗狗币??\n",
      "\n",
      "#狗狗币大涨##怎么购买狗狗币##怎么买狗狗币# L会火大叔的微博视频\n",
      "是一例正面评价 output=0.53\n",
      "狗狗币 看空狗狗币。不要参与！收到的评论区告诉我。我们老老实实做好股市交易就行了。\n",
      "是一例负面评价 output=0.15\n",
      "#狗狗币市值#\n",
      "狗狗币大涨，市值即将超过BNB，这个势头也太猛了吧\n",
      "你看好狗狗币吗？\n",
      "是一例负面评价 output=0.17\n",
      "#比特币大佬看衰狗狗币#【#比特币大牛警告投资者别买狗狗币#】美国亿万富翁投资者迈克-诺沃格拉茨（Mike Novogratz）在最近一次访谈中抨击了瑞波币（XRP），称瑞波币的粉丝就好像特朗普的盲目支持者一样，并建议投资者不要购买狗狗币。 O比特币大牛诺沃格拉茨警告投资者别买狗狗币 L老板联播的微博视频\n",
      "是一例负面评价 output=0.07\n",
      "财经2017年拍卖的850万个狗狗币，现在值多少钱？#狗狗币大涨#\n",
      "是一例负面评价 output=0.42\n",
      "狗狗币#区块链##财经#\n",
      "\n",
      "萌新们——少年们，害怕你们亏，再次更新一下狗狗币\n",
      "\n",
      "狗狗币晚间盘面分析???\n",
      "\n",
      "今天上午发布的盘面分析完美验证，上午的分析中提到了，突破0.63压力区间，看到0.7整数附近\n",
      "\n",
      "行情果不其然，最高拉升到了0.697附近，完美接近0.7整数关口变瀑布，暴跌到了0.61附近\n",
      "\n",
      "操作建议???\n",
      "\n",
      "狗狗币经过了连续两天的暴力拉升，分时周期顶背离比较明显，短线已经走出回调走势 刚刚的小瀑布直接从0.7附近回到了0.61附近，但是行情很可能再次冲高0.7附近就算注定它也会走出一个M头\n",
      "\n",
      "因此短线0.68~0.7区间附近可以继续埋伏空单，搏击形成M头走势\n",
      "\n",
      "下方的短线支撑位，在0.6~0.61区间附近，此位置回踩的话，大概率出现短期反弹\n",
      "\n",
      "下方的强支撑位在0.56~0.57区间附近，如果行情或在此位置可以埋伏稳健多单逢低做多\n",
      "\n",
      "狗狗币当前的行情曲线大概就是二次冲高然后回落\n",
      "\n",
      "最后强调???\n",
      "\n",
      "由于当前的狗狗币已经连续创出了历史新高，如果突破站稳0.7关口的话，那么就要剑指0.8关口\n",
      "\n",
      "如果站不稳0.7在0.7前高压力位再次遇阻的话，就要回踩0.60-0.61区间附近进行蓄势\n",
      "\n",
      "收到\n",
      "\n",
      "转评赞，感谢各位家人\n",
      "\n",
      "新人点这里加入詹姆斯一粉丝7群 收起d\n",
      "是一例正面评价 output=0.84\n",
      "#狗狗币大涨# ????币又双叒叕上热搜？ 你们看好狗狗币的价值吗？\n",
      "是一例负面评价 output=0.32\n",
      "狗狗币价格突破新高\n",
      "你有狗币么\n",
      "不，我只有一条狗命#狗狗币大涨#\n",
      "是一例负面评价 output=0.14\n",
      "#狗狗币市值#狗狗币又暴涨了，有个词叫涨服，今天你不看好他，明天你只能看着别人赚钱流泪。今年入手最不亏的就是bnb和doge，给我继续冲！\n",
      "是一例负面评价 output=0.17\n",
      "#狗狗币大涨# 【#全面复盘狗狗币如何上涨400倍#】4月20日，狗狗币纪念日。《华尔街日报》在首页刊登了狗狗币相关报道，标题为《狗狗币交易赶上线上狂潮》，其中提到狗狗币在2021年的回报率超过8100%，是1998年以来标普500涨幅的2倍多，狗狗币市值大约为500亿美元，超过了万豪国际和福特汽车。\n",
      "\n",
      "狗狗币2021年1月1日开盘报0.004619美元/枚，2021年4月16日最高报价已触及0.47美元/枚，日内暴涨200%，年内价格暴涨超100倍，仅耗时106天。自2020年3月12日最低价0.001158美元以来，最高涨幅超过了400倍。\n",
      "\n",
      "有观点认为，狗狗币的崛起反映了集体信念的力量以及对更理想形式的加密货币的渴望，预示着去中心化必将大兴其道。但狗狗币大涨400倍的背后，其实是名人的带动、散户的狂欢，以及韭菜的博傻心理，狗狗币的泡沫终将破灭。详情请戳链接\n",
      "O全面复盘狗狗币如何上涨400倍 收起d\n",
      "是一例负面评价 output=0.10\n",
      "眼光和运气的较量#狗狗币大涨##几分钟夜聊#\n",
      "是一例正面评价 output=0.57\n",
      "【#狗狗币站上0.6美元#】狗狗币24小时暴涨超50%，站上0.6美元/枚。O狗狗币24小时暴涨超50%，站上0.6美元/枚。\n",
      "是一例正面评价 output=0.87\n",
      "#狗狗币市值#\n",
      "这就已经第三了。。？\n",
      "看来当初还是买少了\n",
      "是一例正面评价 output=0.51\n",
      "第二集，\n",
      "\n",
      "很多人都问我怎么购买狗狗币，\n",
      "\n",
      "2021最新最详细的教程来了??????\n",
      "\n",
      "不懂可以一起交流！\n",
      "\n",
      "#狗狗币大涨##怎么购买狗狗币##怎么买狗狗币# L会火大叔的微博视频\n",
      "是一例负面评价 output=0.32\n",
      "#商旅君的七嘴八舌# #狗狗币大涨#\n",
      "狗狗币真的好可爱呀 小商er们喜欢吗？ 狗狗币\n",
      "是一例正面评价 output=0.62\n",
      "遇见西南医科大的时光#狗狗币#\n",
      "Dogecoin，狗狗币/狗币，诞生于2013年12月8日，基于Scrypt算法，是一款虚拟货币。\n",
      "8年前，为了讽刺比特币圈的投机氛围，狗狗币被两个创始人联手创造出来，并配以夸张戏谑的Doge狗头表情包。\n",
      "不过，具有讽刺意味的是，如今狗狗币与比特币一样，因为投机者的炒作，价格猛涨。\n",
      "2021年愚人节当天，特斯拉CEO马斯克莫名其妙的在推特上给狗狗币站台，号称“SpaceX将把一枚狗狗币送到月球上”。@共青团西南医科大学委员会微博 收起d\n",
      "是一例负面评价 output=0.12\n",
      "# 狗狗币市值 #都是炒起来的，最后赚的还是交易平台，真正有价值的币种没几个，只是一群投机取巧的人在玩，最后80%以上的人都是韭菜，交易所就是镰刀 你会不会买？\n",
      "是一例负面评价 output=0.09\n",
      "#狗狗币大涨# 看我同事买了一些，这两天赚翻了，马斯克的操作神不神？\n",
      "是一例正面评价 output=0.52\n",
      "#狗狗币市值# 狗狗币高度去中心化，不太需要创始人。狗狗币也是0预挖，没给开发预留任何币，他们也并不比其它人更有持币上的优势。正是他们的退出，才促成狗狗币爆发的原因，感谢早期低价抛币的人。你的狗狗币也早期抛了吗？??????O狗狗币市值破800亿 创始人却只赚了辆二手本田\n",
      "是一例负面评价 output=0.16\n",
      "#狗狗币上涨# 原本是开发者“嘲讽”为比特币而生的… 如今却随之疯狂！你们怎么看？ 问下，你们看好它吗？\n",
      "是一例负面评价 output=0.09\n",
      "狗狗币#财经##区块链#\n",
      "\n",
      "我最——尊敬的兄弟们，亲爱的小姐姐们，可爱的萌新们\n",
      "\n",
      "害怕你们亏，更新一下晚间剧本\n",
      "\n",
      "上午剧本回顾???\n",
      "\n",
      "上午的时候一再强调0.52附近就是4小时强支撑位可以搏击稳健多单。\n",
      "\n",
      "狗狗币今天上午的分析完全被验证了，果不其然在0.52附近企稳接着变暴力拉升到了0.65附近，反弹幅度接近25%\n",
      "\n",
      "当前盘面分析???\n",
      "\n",
      "从分时周期来看，当前的狗狗B还处于三角收敛形态之内，这个区间形态就是最近一直强调到0.5~0.7区间 从MACD指标来看，一小时的MACD指标低位金叉，然后迎来一波今天下午的反弹 唯一不足的是成交量并没有有效放大，多个小时周期都缩量明显，在没有放量的情况下，上攻动能就会略减不足。\n",
      "\n",
      "操作建议???\n",
      "\n",
      "短线的压力位：0.63~0.64区间附近\n",
      "\n",
      "重压力位：0.68~0.70区间附近\n",
      "\n",
      "短线支撑位：0.56~0.57区间附近\n",
      "\n",
      "强支撑位：0.52~0.53区间附近\n",
      "\n",
      "可以根据压力位和支撑位情况分布灵活应对\n",
      "\n",
      "收到，拿出诚意\n",
      "\n",
      "“爆赞” 收起d\n",
      "是一例负面评价 output=0.18\n",
      "# 狗狗币大涨 #都是炒起来的，最后赚的还是交易平台，山寨币真正有价值的币种没几个，只是一群投机取巧的人在玩，最后80%以上的人都是韭菜，交易所就是镰刀 你会不会买狗狗币？\n",
      "是一例负面评价 output=0.08\n",
      "狗狗币 从某种角度来说，#DOGE# 和SHIB是交易所格局之争，是流量之争。DOGE是币安的牌，已占先手；SHIB是COINBASE带领着一帮垃圾（OK、HB等）恼羞成怒后打的小格局牌，意图抢回流量。但怎么说呢，一步先步步先。币安就是战国时代的秦朝，DOGE是秦始皇嬴政，必将气吞天下。\n",
      "是一例负面评价 output=0.14\n",
      "# 狗狗币大涨 #都是炒起来的，最后赚的还是交易平台，山寨币真正有价值的币种没几个，只是一群投机取巧的人在玩，最后80%以上的人都是韭菜，交易所就是镰刀 你买不买狗狗币\n",
      "是一例负面评价 output=0.12\n",
      "【#狗狗币创始人只赚了辆二手本田# 如今还在当打工人】#车迷夜聊#\n",
      "\n",
      "马斯克和马库斯，这两个对#狗狗币#至关重要的人，听起来似乎还像是两兄弟，但他们的狗狗币生涯却截然不同：一个在用狗狗币疯狂赚钱造火箭，一个却在2015年狗狗币0.0001美元时清空所有份额，并用赚的钱买了辆二手丰田。\n",
      "\n",
      "戳视频了解什么是狗狗币 L新浪汽车的微博视频 收起d\n",
      "是一例负面评价 output=0.15\n",
      "【市场荒诞剧？今年最牛的资产：暴涨118倍的狗狗币！】虚拟货币狗狗币价格在周三盘中大涨，#狗狗币站上0.6美元# 一度涨超0.68美元，24小时涨幅一度突破56%，#狗狗币续刷历史新高#。相比价格较高的比特币和以太币，狗狗币则更像是一种投机，因为价格非常便宜，散户把它看作是买彩票，因此狗狗币受到Reddit社区这样大量散户的青睐，今年以来的涨幅更是远远超过比特币和以太币等货币。O市场荒诞剧？今年最牛的资产：暴涨118倍的狗狗币！ 收起d\n",
      "是一例负面评价 output=0.09\n",
      "#比特币# 的粉丝和#狗狗币# 的拥趸打起来了，究竟谁能代表数字货币的未来？目前的加密货币恐怕还只是陈胜吴广与楚王项羽，刘邦或许还未登场。比特币与狗狗都是“义军”，是否是友军不知道，一定要比的话，多半好比宋江与方腊。\n",
      "\n",
      "#狗狗币值得长期持有吗#\n",
      "是一例负面评价 output=0.07\n",
      "#狗狗币市值#【狗狗币创始人还在打工，我却提前赚到了养老钱】《财经故事荟》采访了几位早期买入#狗狗币#的投资者：85后张齐因交易所跑路，市值几百万的狗狗币烟消云散；专业人士蛇总，帮朋友实现财富自由，自己却遗憾未早点买入：购买狗狗币致富，大厂打工人不再担心养老↓↓ O狗狗币创始人还在打工，我却提前赚到了养老的钱\n",
      "是一例负面评价 output=0.16\n",
      "#狗狗币市值#【#狗狗币创始人只赚了辆二手本田# 如今还在当打工人】马斯克和马库斯，这两个对#狗狗币#至关重要的人，听起来似乎还像是两兄弟，但他们的狗狗币生涯却截然不同：一个在用狗狗币疯狂赚钱造火箭，一个却在2015年狗狗币0.0001美元时清空所有份额，并用赚的钱买了辆二手本田↓↓O狗狗币市值破800亿：创始人却只赚了辆二手本田 如今还在当打工人 收起d\n",
      "是一例负面评价 output=0.14\n",
      "【比特币大佬Novogratz称#狗狗币#“赌博性”很高】比特币大佬Mike Novogratz表示，狗狗币的大部分价值体现在其“赌博性质”。Novogratz担心，一旦热情消失，将没有开发人员和机构支持狗狗币，做空虽然危险，但是一旦市场热情消失，狗狗币将面临漫漫下行之路。O比特币大佬Novogratz称狗狗币“赌博性”很高\n",
      "是一例负面评价 output=0.10\n",
      "#狗狗币#【还把它当玩笑？#狗狗币市值直逼900亿美元#】加密货币市场曾被鲁比尼描述为“所有泡沫之母”。也许以往各国政府和中央银行数万亿美元的刺激计划可能触发过黄金和高风险股大涨，但这次海量资金奔向的是新生的加密货币市场。O还把它当玩笑？狗狗币市值直逼900亿美元\n",
      "是一例负面评价 output=0.13\n",
      "# 比特币大佬看衰狗狗币 #现在哪有那个价值，都是炒起来的，最后赚的还是交易平台，山寨币真正有价值的币种没几个，只是一群投机取巧的人在玩，最后80%以上的人都是韭菜，交易所就是镰刀 你会买那个？\n",
      "是一例负面评价 output=0.15\n",
      "【#比特币#大牛刚贬完#狗狗币#转眼又捧上天：幸亏我没做空】美国亿万富翁投资者迈克-诺沃格拉茨（Mike Novogratz）在上周一次访谈中建议投资者不要购买狗狗币，但随着狗狗币价格的进一步上涨，他现在承认，他对狗狗币的看法可能过于消极了。诺沃格拉茨长期以来一直认为狗狗币就是一个玩笑。他批评马克·库班用狗狗币出售达拉斯小牛队的门票和相关商品，并在上周警告人们不要购买它。O比特币大牛刚贬完狗狗币转眼又捧上天：幸亏我没做空 收起d\n",
      "是一例负面评价 output=0.09\n",
      "#狗狗币适合年轻人投资吗#在散户们的大力买入下，狗狗币的涨幅在极短时间内达到数十倍，震惊整个币圈。\n",
      "对于新入币圈的朋友们可能对狗狗币还不太熟悉。这个币是个很早期的山寨币，它基本上是比特币的翻版，但是在比特币的基础上主要修改了两处地方：一是将区块出块的时间大大加快，二是将发行量上限设为无限，每年都会有大幅通胀。\n",
      "适不适合年轻人投资，我不觉得这是个问题，投资与年龄无关，暴涨背后都是存在暴跌的风险，本身就不是什么有价值的东西，全凭炒作，最后好多人会一无所有，量力而行，投资需谨慎！ 收起d\n",
      "是一例负面评价 output=0.09\n",
      "【#狗狗币再创历史新高# 马斯克又要上节目了、投资者疯狂涌入】5月8日午间，DOGE强势拉升，短时触及0.74 USDT，再创历史新高。本周六晚马斯克将以主持人的身份，参与录制NBC的热门深夜喜剧秀《周六夜现场》（SNL）。他更于周五傍晚发了一条关于“节目嘉宾”的推特，并附上了狗狗币的配图 狗狗币 >>O狗狗币再创历史新高 马斯克又要上节目了、投资者疯狂涌入 收起d\n",
      "是一例正面评价 output=0.89\n",
      "#狗狗币大涨#听说最近都涨的特别厉害哟！ 你们了解狗狗币吗？\n",
      "是一例负面评价 output=0.33\n",
      "#狗狗币市值#狗狗币疯长，你觉得狗狗币值得投资吗？ 你觉得狗狗币值得投资吗？\n",
      "是一例负面评价 output=0.20\n",
      "#狗狗币大涨# 【马斯克发布狗狗币相关推文，狗狗币短线急涨】4月28日，特斯拉CEO埃隆·马斯克再次发布与狗狗币相关推文，并提到他将于5月8日主持的《周六夜现场》SNL节目。推文发出后，狗狗币短线拉涨约0.05美元，现报0.31美元/枚。\n",
      "\n",
      "今年2月4日，马斯克突然发推“Doge”，狗狗币涨幅迅速攀升50%。随后他又连续发布多条与狗狗币有关的推文：“我们不需要成为亿万富翁就能拥有狗狗币，狗狗币才是人民的数字货币。”“我没喝多，也没情绪低落，心里只有狗狗币。”“狗狗币是世界上最有趣的加密货币。”\n",
      "\n",
      "4月初，马斯克在推特上表示将使用SpaceX把一枚狗狗币带到月球上。消息一出，狗狗币直线拉升，当天大涨15%。\n",
      "O马斯克发布狗狗币相关推文，狗狗币短线急涨 收起d\n",
      "是一例负面评价 output=0.14\n",
      "【1月暴涨10倍，马斯克背书的#狗狗币# 竟被列为“传销币”】2020年全年，狗狗币币价在0.002美元至0.0046美元间缓慢增长，而从年初起至马斯克发文时计算，狗狗币价已经涨了近10倍。彼时狗狗币一度成为全球第五大虚拟货币。而在2017年，央视曾将狗狗币列为资金传销组织。O1月暴涨10倍，马斯克背书的狗狗币竟被列为“传销币”\n",
      "是一例负面评价 output=0.06\n",
      "【马斯克5月8日节目播出前接受街头采访，只聊节目不谈#狗狗币# 】当地时间5月8日，马斯克主持的SNL（周六夜现场）就会播出 到时候再看看他聊不聊狗狗币 L陀螺财经的微博视频\n",
      "是一例正面评价 output=0.55\n",
      "#创事记#【狗狗大涨 大妈沦陷】#狗狗币再创历史新高#狗狗币大涨，54岁的赵女士准备再投入1万元。按照以往的经验，她准备在币价稍微回落的时候再次入手。\n",
      "\n",
      "在名为“钞越自我”的微信群里，很多人和赵女士一样，把几个群管理员视为“最信任的伙伴”。\n",
      "\n",
      "有人相信狗狗币，也有人在吃亏之后不再相信。O狗狗大涨 大妈沦陷 收起d\n",
      "是一例负面评价 output=0.11\n",
      "【#比特币大佬看衰狗狗币#：无知的投资者赶紧卖了吧】在最近的一次访谈中，比特币大佬、加密货币商业银行Galaxy Digital创始人迈克·诺沃格拉茨建议投资者不要购买狗狗币，应该卖掉狗狗币。他表示，不过有很多无知的投资者看到最近狗狗币的大火，都想参与进来。经过新一轮上涨，截至5月2日15时，狗狗币报0.37美元/枚。你知道怎么买狗狗币嘛？ 收起d\n",
      "是一例负面评价 output=0.11\n",
      "【比特币大佬看衰狗狗币上热搜：无知的投资者赶紧卖了吧】和很多圈子一样，币圈似乎也有鄙视链。今日，#比特币大佬看衰狗狗币#直接冲上热搜，更是直言：无知的投资者赶紧卖了吧。O比特币大佬看衰狗狗币上热搜：无知的投资者赶紧卖了吧\n",
      "是一例负面评价 output=0.12\n",
      "【肯德基加拿大分公司接受狗狗币支付】5月5日，肯德基加拿大分公司发推文称：“我们接受现金、银行卡和狗狗币。”#狗狗币#\n",
      "是一例负面评价 output=0.23\n",
      "【#狗狗币续刷历史新高#】狗狗币日内涨超27%，现报0.488美元/枚，续刷历史新高。O狗狗币日内涨超27%，现报0.488美元/枚，续刷历史新高。\n",
      "是一例正面评价 output=0.84\n",
      "#狗狗币大涨# 【狗狗币年内暴涨120倍 马斯克提示谨慎投资加密货币】据报道，狗狗币价格2021年以来已累计上涨超过12000%，比特币价格上个月则短暂升破6万美元，投资者由此将注意力转向极特币、唯链币和SafeMoon等较新的数字资产，以寻找下一个可能蹿红的较廉价替代币。\n",
      "\n",
      "上述报道指出，从一种投机性资产跳转至另一种，表明了较广泛的市场狂热情绪，这种狂热推高了包括白银等大宗商品、股票以及加密货币在内的一系列资产的价格。这一现象还显示出，获得刺激性支票支持以及疫情期间更多时间待在家里的新投资者如何成为了金融市场中一股不稳定的新生力量。\n",
      "\n",
      "不过，据报道，5月7日，特斯拉CEO埃隆马斯克(Elon Musk)在推特上转发一段标题为“马斯克称狗狗币(Dogecoin)可能成为加密货币的未来”的视频，并为视频配文称，加密货币很有前景，但请谨慎投资。\n",
      "O狗狗币年内暴涨120倍 马斯克提示谨慎投资加密货币 收起d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是一例负面评价 output=0.11\n",
      "财经狗狗币24小时涨幅超过40%！在我看来，未来富豪资产配置一定会有加密货币。你们准备好了吗？#狗狗币大涨#\n",
      "是一例负面评价 output=0.11\n",
      "【#狗狗币市值超SpaceX# ，马斯克：谨慎投资】5月7日，特斯拉CEO埃隆·马斯克转发一段标题为“马斯克称狗狗币可能成为加密货币的未来”的视频，并配文称，加密货币很有前景，但请谨慎投资！近来狗狗币涨势迅猛，根据美国证券交易委员会文件，周四狗狗币市值已超780亿美元，比马斯克私人控股火箭公司SpaceX的估值高出40亿美元。L界面Vnews的微博视频 收起d\n",
      "是一例负面评价 output=0.13\n",
      "#狗狗币#【还把它当玩笑？#狗狗币市值直逼900亿美元#】加密货币市场曾被鲁比尼描述为“所有泡沫之母”。也许以往各国政府和中央银行数万亿美元的刺激计划可能触发过黄金和高风险股大涨，但这次海量资金奔向的是新生的加密货币市场。O还把它当玩笑？狗狗币市值直逼900亿美元\n",
      "是一例负面评价 output=0.13\n",
      "【比比特币还疯狂！#狗狗币半年暴涨260倍# 一个玩笑竟“完爆”所有资产类别】在近期的这股加密货币热潮下，谁也没想到最大的赢家竟不是比特币，而是起源于一个玩笑的狗狗币（Dogecoin）。今年以来，狗狗币屡创新高，6个月涨幅超过260倍，市值也一度到达约920亿美元。相比之下，标准普尔500指数在这6个月内仅上涨了19%，而同为加密货币的比特币和以太币仅分别上涨了286%和698%。就连股市宠儿特斯拉自去年11月以来也只上涨了56%。而最荒谬之处在于，这一受到热捧、一路暴涨的币种最初竟是诞生于一个玩笑，创始人为了讽刺比特币圈的投机氛围，以夸张戏谑的Doge狗头表情包作为标志，但后来这个玩笑越开越大，引来马斯克为其站台，将狗狗币的热炒情绪不断带向新高度。O比比特币还疯狂！狗狗币半年暴涨260倍 一个玩笑竟“完爆”所有资产类别 收起d\n",
      "是一例负面评价 output=0.10\n",
      "【贝拉：聊聊比特币、以太坊、狗狗币等】（via YT：贝拉聊财金）观点供参考。#比特币##狗狗币# L全球视频精选Premium的微博视频\n",
      "是一例正面评价 output=0.58\n",
      "【#狗狗币市值超SpaceX# ，马斯克：谨慎投资】5月7日，特斯拉CEO埃隆·马斯克转发一段标题为“马斯克称狗狗币可能成为加密货币的未来”的视频，并配文称，加密货币很有前景，但请谨慎投资！近来狗狗币涨势迅猛，根据美国证券交易委员会文件，周四狗狗币市值已超780亿美元，比马斯克私人控股火箭公司SpaceX的估值高出40亿美元。 L界面Vnews的微博视频 收起d\n",
      "是一例负面评价 output=0.13\n",
      "#比特币大佬看衰狗狗币#无知的投资者赶紧卖了吧，都来买比特币\n",
      "是一例负面评价 output=0.48\n",
      "【#狗狗币再创历史新高#！马斯克又要上节目了！开心到飞起】5月8日午间，DOGE强势拉升，短时触及0.74 USDT，再创历史新高。本周六晚（美国时间）马斯克将以主持人的身份，参与录制NBC的热门深夜喜剧秀《周六夜现场》（SNL）。他更于周五傍晚发了一条关于“节目嘉宾”的推特，并附上了狗狗币的配图。 收起d\n",
      "是一例正面评价 output=0.84\n",
      "#狗狗币大涨#又来割韭菜吗！币圈真是我们了解太少啊！不看不知道，还有哪些你不知道的行业知识，太真实了\n",
      "是一例负面评价 output=0.08\n",
      "#狗狗币大涨#5月4日，狗狗币大涨，狗狗币最近一波趋势涨到0.611美元，狗狗币#狗狗币# 神，牛逼!看来离1美金不是梦。机会和梦想还是要有的，万一实现了呢。附某币圈群总结的新手入门经验总结（此处仅作分享，不作为投资依据）。 #币圈#\n",
      "是一例负面评价 output=0.26\n",
      "【#狗狗币市值超SpaceX# ，马斯克：谨慎投资】5月7日，特斯拉CEO埃隆·马斯克转发一段标题为“马斯克称狗狗币可能成为加密货币的未来”的视频，并配文称，加密货币很有前景，但请谨慎投资！近来狗狗币涨势迅猛，根据美国证券交易委员会文件，周四狗狗币市值已超780亿美元，比马斯克私人控股火箭公司SpaceX的估值高出40亿美元。 L界面Vnews的微博视频 收起d\n",
      "是一例负面评价 output=0.13\n",
      "最近经常看到#狗狗币大涨#上热搜，这种被强行安利的感觉怪怪的。\n",
      "\n",
      "我对币圈不了解，但短期内大涨400倍，可能很多人是把“狗狗币”当作了另一个比特币，想“这次一定要抓住机会”。\n",
      "\n",
      "或许吧，或许又会有一个奇迹。但请永远记住，财富永远是集中在少数人手里的。但所有人都意识到有利可图时，可能就会出现一片又一片绿油油的“韭菜”。\n",
      "\n",
      "最后再声明一下，我是完全的外行，以上全是胡说八道，只想说：投资有风险，买币需谨慎。也欢迎专业人士来科普。 收起d\n",
      "是一例负面评价 output=0.10\n",
      "#分析师警告小心狗狗币赔光所有钱#【分析师警告：狗狗币不会上天 小心赔光所有钱】多位分析师警告称，投资者应该对safemoon和狗狗币（dogecoin）等替代加密货币非常谨慎，其中很多代币不受监管，波动性很大，可能会让买家赔光所有的钱。O分析师警告：狗狗币不会上天 小心赔光所有钱\n",
      "是一例负面评价 output=0.06\n",
      "#狗狗币市值#狗狗币市值大涨，你会买狗狗币吗？ 2济南 你会买狗狗币吗？\n",
      "是一例负面评价 output=0.25\n",
      "#nba球队老板力顶狗狗币#狗狗币又上热搜了啊！球队老板力挺狗狗币啊\n",
      "是一例负面评价 output=0.36\n",
      "#狗狗币大涨# 狗狗币最近一路大涨，给大家来感受一下狗狗币一路大涨的“超神之路”\n",
      "L微天下的微博视频\n",
      "是一例负面评价 output=0.41\n",
      "#800亿市值狗狗币创始人只赚了辆二手车#【狗狗币市值破800亿 创始人却只赚了辆二手本田】进入2021年以来，狗狗币已经上涨超过了11000%，在资本市场上傲视群雄，把比特币、特斯拉这些所谓的佼佼者都踩在脚下，目前市值已高于Twitter、福特等新老巨头，造就了万千散户的财富狂欢。但是谁又能想到，在狗狗币市值一度突破800亿美元的今天，它的发明者如今还只是一个普通的打工人呢？有关于更多狗狗币创始人的消息，欢迎点击链接~O狗狗币市值破800亿 创始人却只赚了辆二手本田 收起d\n",
      "是一例负面评价 output=0.10\n",
      "【#狗狗币市值超越瑞波币市值# 位列第四】Coingecko数据显示，狗狗币市值现已超越瑞波币市值，位列第四。狗狗币市值现报689.42亿美元，XRP市值现报670.26亿美元。O狗狗币市值现已超越瑞波币市值 位列第四\n",
      "是一例负面评价 output=0.26\n",
      "【#比特币大牛警告投资者别买狗狗币#】美国亿万富翁投资者迈克-诺沃格拉茨（Mike Novogratz）在最近一次访谈中抨击了瑞波币（XRP），称瑞波币的粉丝就好像特朗普的盲目支持者一样，并建议投资者不要购买狗狗币。 O比特币大牛诺沃格拉茨警告投资者别买狗狗币 L老板联播的微博视频\n",
      "是一例负面评价 output=0.07\n",
      "#NBA球队老板力顶狗狗币#NBA达拉斯独行侠队老板马克·库班在节目上表示，虽不能说狗狗币是世界上最好的投资，但要比彩票好得多。你看好狗狗币吗? 你看好狗狗币吗?\n",
      "是一例负面评价 output=0.20\n",
      "【#狗狗币适合年轻人投资吗#】4月28日下午，#狗狗币大涨#再登微博热搜，消息面上，特斯拉CEO埃隆·马斯克再次发布与狗狗币相关推文，并提到他将于5月8日主持的《周六夜现场》SNL节目。你有投资狗狗币的打算吗？狗狗币的暴涨是一个泡沫吗？O#狗狗币大涨#再登微博热搜 4年暴涨2100倍的神话会破灭吗？\n",
      "是一例负面评价 output=0.08\n",
      "#狗狗币上涨# 马哥今天没发推文，狗币持续来劲，币圈老铁们，啥情况？难道直接上1美元？\n",
      "是一例负面评价 output=0.21\n",
      "【币圈鄙视链？#比特币大佬看衰狗狗币#：无知的投资者赶紧卖了吧】在最近的一次访谈中，比特币大佬、加密货币商业银行Galaxy Digital创始人迈克·诺沃格拉茨建议投资者不要购买狗狗币，应该卖掉狗狗币。他表示，不过有很多无知的投资者看到最近狗狗币的大火，都想参与进来。经过新一轮上涨，截至5月2日15时，狗狗币报0.37美元/枚。 L老板联播的微博视频 收起d\n",
      "是一例负面评价 output=0.11\n",
      "#比特币大佬看衰狗狗币#\n",
      "\n",
      "两边都是不停的加肥皂水\n",
      "\n",
      "不停的吹，一边吹一边说\n",
      "\n",
      "你看我们的泡泡又大又漂亮\n",
      "\n",
      "就是让你一起加入他们一起吹\n",
      "\n",
      "大家总觉得自己肯定不是最后一棒\n",
      "\n",
      "所以说狗咬狗看看戏吃吃瓜就好了\n",
      "是一例负面评价 output=0.17\n",
      "【#狗狗币创始人#还在打工 我却提前赚到了养老的钱】#狗狗币市值# 因玩笑而诞生的狗狗币，如今更像一个现实版的荒诞“盲盒”，深入其中的投资者，有人一夜暴富，有人却竹篮打水一场空，而即便是那些暴富者，也如同做梦一般，连呼“想不到”。\n",
      "\n",
      "媒体先后采访了几位早期就买入狗狗币的投资者：85后张齐因交易所跑路，市值几百万的狗狗币烟消云散；90后刘同，因狗狗币被传销集团盯上，便不再信任，急于出手，最后一无所获；85后张伟，买狗狗币收入翻倍，只恨当时买太少：专业人士蛇总，帮朋友实现财富自由，自己却遗憾未早点买入狗狗币：购买狗狗币意外致富，互联网大厂打工人不再担心未来养老。O狗狗币创始人还在打工 我却提前赚到了养老的钱 收起d\n",
      "是一例负面评价 output=0.11\n",
      "【远超其他加密货币，狗狗币 1 月以来暴涨 12000％】据报道，当地时间周三，狗狗币一度飙升至 69 美分的历史高点。最近几个月，这一加密货币的价值飙升……详情点击：O远超其他加密货币，狗狗币 1 月以来暴涨 12000％\n",
      "是一例负面评价 output=0.12\n",
      "[0.13495362, 0.07898942, 0.3161262, 0.13179445, 0.53856283, 0.22287047, 0.13298634, 0.15512624, 0.08768916, 0.52564365, 0.15230048, 0.17231119, 0.07381925, 0.41931713, 0.84159756, 0.3213745, 0.14288524, 0.16823635, 0.09958127, 0.57253176, 0.86895716, 0.5077516, 0.32118732, 0.6205867, 0.12437862, 0.090504885, 0.52003145, 0.16486257, 0.09033659, 0.18162185, 0.08316046, 0.14246467, 0.117584646, 0.14784575, 0.08769491, 0.065601975, 0.15794656, 0.13650483, 0.10052967, 0.1333021, 0.15167186, 0.08664641, 0.0868288, 0.88828164, 0.33396268, 0.19790831, 0.13788494, 0.057372153, 0.553874, 0.11190143, 0.10535985, 0.12200311, 0.2264697, 0.842831, 0.11398214, 0.111783236, 0.12544847, 0.1333021, 0.10086337, 0.5840524, 0.12544847, 0.47714356, 0.838765, 0.07793322, 0.26047847, 0.12544847, 0.09577346, 0.060801297, 0.24819893, 0.3552006, 0.4095329, 0.10157597, 0.25688526, 0.07405931, 0.2041406, 0.08275905, 0.21267486, 0.112645775, 0.17076847, 0.10956794, 0.123949945]\n"
     ]
    }
   ],
   "source": [
    "preouts = []\n",
    "for text in testcom2:\n",
    "    try:\n",
    "        preout = predict_sentiment(text)\n",
    "        preouts.append(preout)\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "print(preouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c7d2f94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13495362,\n",
       " 0.07898942,\n",
       " 0.3161262,\n",
       " 0.13179445,\n",
       " 0.53856283,\n",
       " 0.22287047,\n",
       " 0.13298634,\n",
       " 0.15512624,\n",
       " 0.08768916,\n",
       " 0.52564365,\n",
       " 0.15230048,\n",
       " 0.17231119,\n",
       " 0.07381925,\n",
       " 0.41931713,\n",
       " 0.84159756,\n",
       " 0.3213745,\n",
       " 0.14288524,\n",
       " 0.16823635,\n",
       " 0.09958127,\n",
       " 0.57253176,\n",
       " 0.86895716,\n",
       " 0.5077516,\n",
       " 0.32118732,\n",
       " 0.6205867,\n",
       " 0.12437862,\n",
       " 0.090504885,\n",
       " 0.52003145,\n",
       " 0.16486257,\n",
       " 0.09033659,\n",
       " 0.18162185,\n",
       " 0.08316046,\n",
       " 0.14246467,\n",
       " 0.117584646,\n",
       " 0.14784575,\n",
       " 0.08769491,\n",
       " 0.065601975,\n",
       " 0.15794656,\n",
       " 0.13650483,\n",
       " 0.10052967,\n",
       " 0.1333021,\n",
       " 0.15167186,\n",
       " 0.08664641,\n",
       " 0.0868288,\n",
       " 0.88828164,\n",
       " 0.33396268,\n",
       " 0.19790831,\n",
       " 0.13788494,\n",
       " 0.057372153,\n",
       " 0.553874,\n",
       " 0.11190143,\n",
       " 0.10535985,\n",
       " 0.12200311,\n",
       " 0.2264697,\n",
       " 0.842831,\n",
       " 0.11398214,\n",
       " 0.111783236,\n",
       " 0.12544847,\n",
       " 0.1333021,\n",
       " 0.10086337,\n",
       " 0.5840524,\n",
       " 0.12544847,\n",
       " 0.47714356,\n",
       " 0.838765,\n",
       " 0.07793322,\n",
       " 0.26047847,\n",
       " 0.12544847,\n",
       " 0.09577346,\n",
       " 0.060801297,\n",
       " 0.24819893,\n",
       " 0.3552006,\n",
       " 0.4095329,\n",
       " 0.10157597,\n",
       " 0.25688526,\n",
       " 0.07405931,\n",
       " 0.2041406,\n",
       " 0.08275905,\n",
       " 0.21267486,\n",
       " 0.112645775,\n",
       " 0.17076847,\n",
       " 0.10956794,\n",
       " 0.123949945]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6917e55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "45816743",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24133001\n"
     ]
    }
   ],
   "source": [
    "surge2 = mean(preouts)\n",
    "print(surge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "464cb67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the misclassified texts\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.T[0]\n",
    "y_pred = [1 if p>= 0.5 else 0 for p in y_pred]\n",
    "y_pred = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2febf640",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_actual = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a38296e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the misclassified index\n",
    "misclassified = np.where( y_pred != y_actual )[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6a9d670e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5,  14,  15,  21,  23,  24,  30,  38,  42,  59,  73,  87,  89,\n",
       "        93, 101, 123, 125, 127, 128, 130, 135, 138, 160, 177, 182, 189,\n",
       "       202, 211, 214, 218, 223, 228, 238, 244, 246, 253, 258, 267, 277,\n",
       "       285, 286, 292, 302, 305, 311, 347, 349, 352, 357, 360, 365, 373,\n",
       "       394], dtype=int64)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misclassified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "cbc7b244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    }
   ],
   "source": [
    "# Output the misclassified indexs\n",
    "len(misclassified)\n",
    "print(len(misclassified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "24f3f11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                        由于2007年新装修有一些新问题可能还没来得及解决我因为工作需要经常要住那里所以慎重的提出以下意见建议：1新装修后 的淋浴间淋浴喷头的位置都太高我换了房间还是一样很不好用2新开业后的一些管理和服务还很不到位尤其是前台入住和结帐时代效率太低每次结帐都超过10分钟好像不符合 宾馆的要求\n",
      "预测的分类 0\n",
      "实际的分类 1.0\n"
     ]
    }
   ],
   "source": [
    "# Find a sample of misclassified errors.\n",
    "idx=101\n",
    "print(reverse_tokens(X_test[idx]))\n",
    "print('预测的分类', y_pred[idx])\n",
    "print('实际的分类', y_actual[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "dd8b436a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                 还是很幽静设施也不错但是服务水平和以前 比急剧下滑了接线员和客房服务中心的服务极差幸好我不是很在乎\n",
      "预测的分类 1\n",
      "实际的分类 1.0\n"
     ]
    }
   ],
   "source": [
    "idx=1\n",
    "print(reverse_tokens(X_test[idx]))\n",
    "print('预测的分类', y_pred[idx])\n",
    "print('实际的分类', y_actual[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd415345",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
